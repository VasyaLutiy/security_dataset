# Security Dataset Parser

Инструмент для создания структурированного датасета по компьютерной безопасности из коллекции файлов.

## Возможности

- Многопоточная обработка индексных файлов
- Извлечение и структурирование метаданных
- Категоризация и классификация данных
- Мониторинг процесса обработки
- SQLite база данных для хранения результатов
- Режим тестового запуска (dry-run)

## Требования

- Python 3.8+
- Зависимости из requirements.txt

## Установка

```bash
# Клонирование репозитория
git clone [repository_url]
cd security_dataset

# Установка зависимостей
pip install -r requirements.txt
```

## Использование

### 1. Инициализация базы данных

```bash
python tools/db_init.py path/to/database.db
```

### 2. Тестовый запуск (предварительный просмотр)

```bash
python tools/run_processing.py --dry-run path/to/database.db path/to/root/directory
```

Этот режим позволяет:
- Увидеть список найденных индексных файлов
- Просмотреть образцы данных из каждого файла
- Проверить корректность парсинга без записи в БД
- Оценить объем данных для обработки

### 3. Полная обработка файлов

```bash
python tools/run_processing.py path/to/database.db path/to/root/directory
```

При запуске вы увидите:
- Информацию о системных ресурсах
- Список найденных файлов
- Прогресс-бар обработки
- Мониторинг CPU и RAM
- Статистику обработки

## Структура проекта

```
security_dataset/
├── src/
│   ├── database/
│   │   ├── models.py      # Модели данных
│   │   └── db_manager.py  # Менеджер базы данных
│   ├── parsers/
│   │   ├── base_parser.py # Базовый класс парсера
│   │   └── index_parser.py # Парсер индексных файлов
│   └── main.py
├── tools/
│   ├── db_init.py        # Инициализация БД
│   ├── test_parser.py    # Тестирование парсера
│   ├── process_indexes.py # Обработка файлов
│   └── run_processing.py # Запуск обработки
├── requirements.txt
└── README.md
```

## Особенности реализации

### Многопоточная обработка

- Использование ProcessPoolExecutor для параллельной обработки файлов
- Пакетная обработка для оптимизации производительности
- Мониторинг системных ресурсов
- Автоматическое определение оптимального числа процессов

### База данных

- SQLite с поддержкой конкурентного доступа
- Структурированное хранение метаданных
- Поддержка JSON для сложных данных
- Оптимизированные индексы для быстрого поиска

### Мониторинг

- Отслеживание прогресса обработки
- Мониторинг использования CPU и памяти
- Детальное логирование
- Статистика обработки файлов

## Форматы данных

### Индексные файлы

```text
/// File Name: example.zip
Description:
Authored by Example Author
Tool description text
tags | tool, category
systems | linux, windows
MD5 | hash_value
```

### База данных

- Таблица files: информация о файлах
- Таблица annotations: аннотации и описания
- Таблица content: содержимое и метаданные

## Мониторинг и логирование

### Логи
- process_indexes.log - для процесса обработки
- processing.log - для основного процесса

### Статистика
- Количество обработанных файлов
- Количество извлеченных записей
- Статистика ошибок
- Использование системных ресурсов

## Известные ограничения

- Требуется оптимизация памяти для больших файлов
- Необходима доработка обработки различных кодировок
- SQLite может стать узким местом при большом количестве параллельных процессов

## Лицензия

MIT License